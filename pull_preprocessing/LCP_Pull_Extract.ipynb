{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LCP_Pull_Extract.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCKJ9rrLqKvD3LdPTTApgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atjoelpark/ml-disparities-mit/blob/master/pull_preprocessing/LCP_Pull_Extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ou01sFNHqII"
      },
      "source": [
        "# Pull and Extraction of LCP PMIDs\n",
        "\n",
        "This notebook provides documentation and code for pulling metadata for a list of PMID IDs.\n",
        "\n",
        "Reference: https://lcp.mit.edu/publications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5F68NWGnNJT"
      },
      "source": [
        "# Customization\n",
        "# Please enter in the pathway in your Google Drive (after /content/drive/) that you would like your files to be saved into\n",
        "# Users will only need to modify this code then run all the cells in order\n",
        "google_drive_url = \"\"\n",
        "folder_to_save_in_google_drive = \"/content/drive/My Drive/Research/Pubmed/MIT_publications\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i7Z0eLsnKp3"
      },
      "source": [
        "# Libraries and Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9gwfQKjHHOF"
      },
      "source": [
        "# Importing libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import re \n",
        "import requests"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2CMbEmxcI52",
        "outputId": "ced87e62-5e87-4f2b-b109-f30f01950d85"
      },
      "source": [
        "# Mounting Google Drive if using Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(f'/content/drive/{google_drive_url}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHftg_fXkRLd"
      },
      "source": [
        "## Defining Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI4WyW-wlVY0"
      },
      "source": [
        "# Installing E-utilities Entrez Direct\n",
        "def e_utilities_install():\n",
        "  \"\"\"\n",
        "  Installs e_utilities\n",
        "  Reference: https://www.ncbi.nlm.nih.gov/books/NBK179288/\n",
        "  \"\"\"\n",
        "  !curl -L https://www.ncbi.nlm.nih.gov/books/NBK179288/bin/install-edirect.sh > install-edirect.sh\n",
        "  !bash install-edirect.sh -y\n",
        "  !echo 'export PATH=\\$PATH:\\$HOME/edirect' >> $HOME/.bash_profile\n",
        "  !rm install-edirect.sh"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ0eaIJLcmFa"
      },
      "source": [
        "# Setting development environment for Selenium\n",
        "def setup_dev_environment():\n",
        "  \"\"\"\n",
        "  Installs chromium, driver and selenium\n",
        "  Sets options to be headless\n",
        "  Opens a website and prepares Selenium for use\n",
        "  Returns: webdriver\n",
        "  \"\"\"\n",
        "\n",
        "  # install chromium, its driver, and selenium\n",
        "  !apt update\n",
        "  !apt install chromium-chromedriver\n",
        "  !pip install selenium\n",
        "  !pip install webdriver_manager\n",
        "  # set options to be headless, ..\n",
        "  from selenium import webdriver\n",
        "  options = webdriver.ChromeOptions()\n",
        "  options.add_argument('--headless')\n",
        "  options.add_argument('--no-sandbox')\n",
        "  options.add_argument('--disable-dev-shm-usage')\n",
        "  # open it, go to a website, and get results\n",
        "  print(\"Chromium, Driver and Selenium successfully started....\")\n",
        "  return webdriver.Chrome(options=options)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG8QXqbkYL8G"
      },
      "source": [
        "# Defining Functions\n",
        "def pull_pmid(year: int, wd) -> list:\n",
        "  \"\"\" \n",
        "  This takes in a year as an argument and reads the PMID IDs for each year within https://lcp.mit.edu/publications\n",
        "\n",
        "  Dependencies: Selenium, chromium-chromedriver, webdriver_manager, re\n",
        "  @param year: This int contains the year to scrape from in https://lcp.mit.edu/publications\n",
        "  @param wb: Passes in the webdriver for Selenium\n",
        "  @return: a list of PMIDs\n",
        "  @raise TypeError: raises an exception\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Uses Selenium to search by CSS\n",
        "    URL = f'https://lcp.mit.edu/publications#P_{year}'\n",
        "    wd.get(URL)\n",
        "    # Click on the appropriate year tag\n",
        "    l = wd.find_element_by_link_text(str(year))\n",
        "    l.click()\n",
        "    _links = wd.find_elements_by_css_selector('.bib2xhtml a+ a')\n",
        "\n",
        "    # Initiating an empty PMID list and appends to list with all PMID IDs\n",
        "    _pmid_list = []\n",
        "    for i in _links:\n",
        "      tmp_search = re.findall(r'\\(PMID:.*\\)', i.text)\n",
        "      if tmp_search:\n",
        "        _pmid_list.append(tmp_search)\n",
        "\n",
        "    # Flattends the list\n",
        "    _pmid_list = [item for sublist in _pmid_list for item in sublist]\n",
        "\n",
        "    # Extracts out only integers and removes text and special characters. \n",
        "    # Returns the list\n",
        "    _pmid_list = [int(re.findall(r'\\d+', i)[0]) for i in _pmid_list]\n",
        "    return _pmid_list\n",
        "\n",
        "  except TypeError as e:\n",
        "    print(\"Error raised while pulling PMID...\")\n",
        "    print(e)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXr5QGofH8XC"
      },
      "source": [
        "# Defining Functions\n",
        "def pull_pmid_metadata(pmid: list) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  This is dependent on E-utilities. The input parameter is a list of PMIDs.\n",
        "  The output is a Pandas DataFrame with the following columns:\n",
        "\n",
        "  1. PMID\n",
        "  2. PubMed Article Title\n",
        "  3. DateCompleted (Year_Month_Day)\n",
        "  4. DateRevised (Year_Month_Day)\n",
        "  5. Journal Title\n",
        "  6. Publication Date (Year_Month_Day)\n",
        "  7. Abstract\n",
        "  8. Author FirstName_LastName_Affiliation (Note that that three values are\n",
        "  separated by \"_\". If an author has affilitations to multiple institions, the\n",
        "  institutions are separated by the character \"/\".)\n",
        "\n",
        "  @param pmid: Takes a list of PMIDs produced by function pull_pmid\n",
        "  @return: Returns a Pandas DataFrame\n",
        "  @raise keyError: raises an exception\n",
        "  \"\"\"\n",
        "  columns = [\"PMID\", \"PubMed_Article_Title\", \"Date_Completed_Year\", \n",
        "             \"Date_Completed_Month\", \"Date_Completed_Day\", \"Date_Revised_Year\", \n",
        "             \"Date_Revised_Month\", \"Date_Revised_Day\", \"Journal_Title\",\n",
        "             \"Publication_Date_Year\", \"Publication_Date_Month\", \"Publication_Date_Day\",\n",
        "             \"Abstract\", \"AuthorFirstName_AuthorLastName_Affiliation\"]\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  for id, i in enumerate(pmid):\n",
        "    try:\n",
        "      _temp = f'''$HOME/edirect/efetch -db pubmed -id {i} -format xml \\\n",
        "| $HOME/edirect/xtract -pattern PubmedArticle -tab \"|\" -def \"NULL\" -sep \",\" -element MedlineCitation/PMID ArticleTitle \\\n",
        "DateCompleted/Year DateCompleted/Month DateCompleted/Day DateRevised/Year DateRevised/Month DateRevised/Day Journal/Title \\\n",
        "PubDate/Year PubDate/Month PubDate/Day AbstractText \\\n",
        "-block Author -tab \"/\" -def \"NULL\" -sep \"_\" -element ForeName,LastName,Affiliation'''\n",
        "\n",
        "      _result = !{_temp}\n",
        "      _temp = _result[0].split(\"|\")\n",
        "\n",
        "      for _count, _value in enumerate(_temp):\n",
        "        df.loc[id,columns[_count]] = _value\n",
        "        \n",
        "    except Exception as e:\n",
        "      print(\"Error Raised when Querying Unix EDirect...\")\n",
        "      print(e)\n",
        "\n",
        "  # Prior to returning df\n",
        "  # If any cells have empty values, convert to NULL\n",
        "  df = df.replace(r'', \"NULL\", regex=True)\n",
        "  return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLhETuQhmGb6"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxvNWj7AlMFa",
        "outputId": "375826a8-edf4-4631-d94c-57520d6d4edf"
      },
      "source": [
        "%%time\n",
        "# Install E-utilities, when prompted \"Would you like to do that automatically now?\" Please select 'y'.\n",
        "e_utilities_install()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   665  100   665    0     0   3136      0 --:--:-- --:--:-- --:--:--  3136\n",
            "\n",
            "Entrez Direct has been successfully downloaded and installed.\n",
            "\n",
            "In order to complete the configuration process, please execute the following:\n",
            "\n",
            "  echo \"export PATH=\\${PATH}:/root/edirect\" >> $HOME/.bashrc\n",
            "\n",
            "or manually edit the PATH variable assignment in your .bashrc file.\n",
            "\n",
            "Would you like to do that automatically now? [y/N]\n",
            "y\n",
            "OK, done.\n",
            "CPU times: user 130 ms, sys: 49.6 ms, total: 180 ms\n",
            "Wall time: 15.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fxofv-JiCK5",
        "outputId": "b960860a-e837-49dc-ed0b-e37b6c8af135"
      },
      "source": [
        "%%time \n",
        "# Sets up Web Driver\n",
        "wd = setup_dev_environment()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,263 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [510 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,421 kB]\n",
            "Get:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:18 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [66.2 kB]\n",
            "Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Ign:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [695 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,786 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,196 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [914 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [39.4 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,699 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [544 kB]\n",
            "Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Get:29 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.1 kB]\n",
            "Fetched 13.6 MB in 4s (3,285 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "104 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 104 not upgraded.\n",
            "Need to get 86.0 MB of archives.\n",
            "After this operation, 298 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 91.0.4472.101-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 91.0.4472.101-0ubuntu0.18.04.1 [76.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 91.0.4472.101-0ubuntu0.18.04.1 [3,937 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 91.0.4472.101-0ubuntu0.18.04.1 [4,837 kB]\n",
            "Fetched 86.0 MB in 4s (23.4 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_91.0.4472.101-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting selenium\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "\u001b[K     |████████████████████████████████| 904 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-3.4.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver_manager) (2.23.0)\n",
            "Collecting configparser\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting crayons\n",
            "  Downloading crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (3.0.4)\n",
            "Installing collected packages: colorama, crayons, configparser, webdriver-manager\n",
            "Successfully installed colorama-0.4.4 configparser-5.0.2 crayons-0.4.0 webdriver-manager-3.4.2\n",
            "Chromium, Driver and Selenium successfully started....\n",
            "CPU times: user 442 ms, sys: 101 ms, total: 544 ms\n",
            "Wall time: 40.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYW9zGS9DpxZ",
        "outputId": "a829477f-e563-418b-e00f-6ed55f09345d"
      },
      "source": [
        "%%time\n",
        "# Creating a dictionary with keys = years, values = list of PMIDs corresponding to the year\n",
        "MIT_publications = {}\n",
        "for year in range(2003, 2021, 1):\n",
        "  MIT_publications[year] = pull_pmid(year, wd)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.2 s, sys: 615 ms, total: 12.8 s\n",
            "Wall time: 1min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3-TBKPOEyTV"
      },
      "source": [
        "# Looping through the dictionary keys and returning pandas dataframes\n",
        "# Saving to Google Colab all the CSV files\n",
        "MIT_publications_df = {}\n",
        "for year in range(2003, 2021, 1):\n",
        "  MIT_publications_df[year] = pull_pmid_metadata(MIT_publications[year])\n",
        "  exec(f'MIT_publications_{year} = MIT_publications_df[{year}]')\n",
        "  exec(f'MIT_publications_{year}.to_csv(\"{folder_to_save_in_google_drive}/MIT_publications_{year}.csv\", index=False)')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hK2VudqHlId",
        "outputId": "6bc61a15-1543-41da-88f9-2eb769e2939c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pull_pmid(2003, wd)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12669985, 32520977]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XITlTZDpVYMf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}